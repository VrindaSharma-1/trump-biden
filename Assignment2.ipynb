{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PURGH45yEjhX"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJSPRiPmEjgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from string import punctuation\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAjpaWFrEjgo",
        "colab_type": "text"
      },
      "source": [
        "# Part B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNppOi6WEjgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweets = pd.read_csv('6ktweets.csv')\n",
        "\n",
        "def remove_punctuation(item):\n",
        "    for p in punctuation:\n",
        "        item = item.lstrip().replace(p,'')\n",
        "    return item\n",
        "\n",
        "def conv_lowercase(x):\n",
        "    return x.lower()\n",
        "\n",
        "tweets['clean_tweets'] = tweets['tweets'].apply(remove_punctuation).apply(conv_lowercase)\n",
        "#tweets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRuAuHICEjgs",
        "colab_type": "code",
        "colab": {},
        "outputId": "d47e5ce1-0e34-4be0-aab4-61aeabc7c121"
      },
      "source": [
        "nltk.download()\n",
        "tweets['word_freq_list'] = tweets['clean_tweets'].apply(word_tokenize).apply(set).apply(list)\n",
        "\n",
        "# Remove stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def remove_stopwords(s):\n",
        "    return [w for w in s if not w in stop_words] \n",
        "\n",
        "tweets['word_freq_list'] = tweets['word_freq_list'].apply(remove_stopwords)\n",
        "\n",
        "# Creating a list of all the words in the comments to count word frequency in the next step\n",
        "count = []\n",
        "for i in range(len(tweets)):\n",
        "    count+=tweets['word_freq_list'][i]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puIQrG3NEjgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fetching the frequency of words\n",
        "from nltk import FreqDist\n",
        "word_freq = nltk.FreqDist(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DB0BNFSSEjgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#identified key issues\n",
        "\n",
        "#trump issues\n",
        "immigration = ['mexican', 'wall', 'immigrate', 'mexico', 'illegals', 'immigrants', 'immigrant']\n",
        "impeach = ['impeachment', 'impeached', 'trumpimpeachment', 'impeachtrump']\n",
        "foreign_relations = ['ukraine', 'isis', 'syria', 'china' ,'iran']\n",
        "\n",
        "#biden issues\n",
        "economy = ['job', 'jobs', 'money', 'taxes', 'taxpayer', 'economys', 'trumpeconomy']\n",
        "education = [ 'college', 'school' ,'educate' ,'students' , 'student']\n",
        "gun_control = ['control','weapons', 'weapon','guns', 'gun']\n",
        "\n",
        "#replacements for trump and biden\n",
        "trump = ['donaldtrump', 'realdonaldtrump',  'trump2020','trumps', 'donald','realtrump','MAGA','KAG','Trump']\n",
        "biden = ['joebiden', 'joes','bidens', 'joe','biden']\n",
        "\n",
        "attributes = immigration + impeach+ foreign_relations + economy + trump + biden +education + gun_control"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSVnm8PuEjg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#replacing words with key issues\n",
        "key_issues = pd.DataFrame()\n",
        "key_issues['attribute'] = attributes\n",
        "key_issues['general_attribute'] = ''\n",
        "\n",
        "key_issues['general_attribute'][0:len(immigration)] = 'immigration'\n",
        "key_issues['general_attribute'][len(immigration):len(immigration)+len(impeach)] = 'impeach'\n",
        "key_issues['general_attribute'][len(immigration)+len(impeach):len(immigration)+len(impeach)+len(foreign_relations)] = 'foreign_relations'\n",
        "key_issues['general_attribute'][len(immigration)+len(impeach)+len(foreign_relations):len(immigration)+len(impeach)+len(foreign_relations)+len(economy)] = 'economy'\n",
        "key_issues['general_attribute'][len(immigration)+len(impeach)+len(foreign_relations)+ len(economy):len(immigration)+len(impeach)+len(foreign_relations)+len(economy)+len(trump)] = 'trump'\n",
        "key_issues['general_attribute'][len(immigration)+len(impeach)+len(foreign_relations)+len(economy)+len(trump):len(immigration)+len(impeach)+len(foreign_relations)+len(economy)+len(trump)+len(biden)] = 'biden'\n",
        "key_issues['general_attribute'][len(immigration)+len(impeach)+len(foreign_relations)+len(economy)+len(trump)+ len(biden):len(immigration)+len(impeach)+len(foreign_relations)+len(economy)+len(trump)+len(biden) + len(education)] = 'education'\n",
        "key_issues['general_attribute'][len(immigration)+len(impeach)+len(foreign_relations)+len(economy)+len(trump)+ len(biden)+ len(gun_control):len(immigration)+len(impeach)+len(foreign_relations)+len(economy)+len(trump)+len(biden) + len(education)+len(gun_control)] = 'gun_control'\n",
        "#key_issues"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSUPPFn9Ejg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_to_attributes(s):\n",
        "    s = \" \".join(str(x) for x in s)\n",
        "    for i in key_issues.index.values:\n",
        "        s = s.replace(key_issues[\"attribute\"][i].lower(),key_issues[\"general_attribute\"][i].lower())\n",
        "    return s\n",
        "\n",
        "tweets['comments_attributes_replace'] = tweets['word_freq_list'].apply(word_to_attributes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1wB_-j4Ejg4",
        "colab_type": "text"
      },
      "source": [
        "### C.To isolate a candidate and an issue, you have to write a parser that selects tweets that mention a candidate, takes a window around an issue, and chops off everything else, as shown in class.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFRtfjOdEjg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#making list of tweets that mention trump and list of tweets that mention biden\n",
        "all_ = tweets['comments_attributes_replace'].apply(word_tokenize).apply(set).apply(list)\n",
        "all_ = all_.tolist()\n",
        "t =[]\n",
        "b =[]\n",
        "for i in all_: \n",
        "    for j in set(i):\n",
        "        if j == 'trump':\n",
        "            t.append(i)\n",
        "        elif j == 'biden':\n",
        "            b.append(i)             "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJxvEk2SEjg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculating total no of tweets that mention each of these key issues\n",
        "economy =[]\n",
        "immigration =[]\n",
        "foreign_relations=[]\n",
        "impeach=[]\n",
        "for j in all_:\n",
        "    for k in j:\n",
        "        if k == 'economy':\n",
        "            economy.append(j)\n",
        "        if k == 'immigration':\n",
        "            immigration.append(j)\n",
        "        if k =='foreign_relations':\n",
        "            foreign_relations.append(j)\n",
        "        if k == 'impeach':\n",
        "            impeach.append(j) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNC5wMbREjg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculating total number of tweets that mention both key issues and trump\n",
        "economy_trump =[]\n",
        "immigration_trump =[]\n",
        "foreign_relations_trump=[]\n",
        "impeach_trump =[]\n",
        "\n",
        "for j in t:\n",
        "    for k in j:\n",
        "        if k == 'economy':\n",
        "            economy_trump.append(j)\n",
        "        if k == 'immigration':\n",
        "            immigration_trump.append(j)\n",
        "        if k =='foreign_relations':\n",
        "            foreign_relations_trump.append(j)\n",
        "        if k == 'impeach':\n",
        "            impeach_trump.append(j)           "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE0Cey7SEjg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculating total number of tweets that mention both key issues and biden\n",
        "economy_biden =[]\n",
        "immigration_biden =[]\n",
        "foreign_relations_biden=[]\n",
        "impeach_biden =[]\n",
        "\n",
        "for c in b:\n",
        "    for b1 in set(c):\n",
        "        if b1 == 'economy':\n",
        "            economy_biden.append(c)\n",
        "            continue;\n",
        "        if b1 == 'immigration':\n",
        "            immigration_biden.append(c)\n",
        "            continue; \n",
        "        if b1 =='foreign_relations':\n",
        "            foreign_relations_biden.append(c) \n",
        "            continue;\n",
        "        if b1 == 'impeach':\n",
        "            impeach_biden.append(c)  \n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTi4w9DQEjhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lift analysis for trump and biden\n",
        "\n",
        "#trump\n",
        "lift_economy_trump = (len(tweets)*len(economy_trump))/(len(t)*len(economy))\n",
        "lift_immigration_trump = (len(tweets)*len(immigration_trump))/(len(t)*len(immigration))\n",
        "lift_foriegn_relations_trump = (len(tweets)*len(foreign_relations_trump))/(len(t)*len(foreign_relations))\n",
        "lift_impeach_trump = (len(tweets)*len(impeach_trump))/(len(t)*len(impeach))\n",
        "\n",
        "#biden\n",
        "lift_economy_biden = (len(tweets)*len(economy_biden))/(len(b)*len(economy))\n",
        "lift_immigration_biden = (len(tweets)*len(immigration_biden))/(len(b)*len(immigration))\n",
        "lift_foriegn_relations_biden = (len(tweets)*len(foreign_relations_biden))/(len(b)*len(foreign_relations))\n",
        "lift_impeach_biden = (len(tweets)*len(impeach_biden))/(len(b)*len(impeach))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v123V0EdEjhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [[lift_economy_trump, lift_immigration_trump, lift_foriegn_relations_trump, lift_impeach_trump], [lift_economy_biden, lift_immigration_biden, lift_foriegn_relations_biden,lift_impeach_biden]]\n",
        "lift = pd.DataFrame(data, columns = ['Economy', 'Immigration', 'Foreign Relations', 'Impeach'])\n",
        "lift.rename(index = {0: \"Trump\", 1:\"Biden\"},  inplace = True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kelzMN-GEjhF",
        "colab_type": "code",
        "colab": {},
        "outputId": "a022d9e0-dd52-48c2-82f9-09fff647d552"
      },
      "source": [
        "lift"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Economy</th>\n",
              "      <th>Immigration</th>\n",
              "      <th>Foreign Relations</th>\n",
              "      <th>Impeach</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>Trump</td>\n",
              "      <td>0.918829</td>\n",
              "      <td>0.995025</td>\n",
              "      <td>1.188502</td>\n",
              "      <td>1.293532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Biden</td>\n",
              "      <td>1.794325</td>\n",
              "      <td>0.622407</td>\n",
              "      <td>2.489627</td>\n",
              "      <td>0.398340</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Economy  Immigration  Foreign Relations   Impeach\n",
              "Trump  0.918829     0.995025           1.188502  1.293532\n",
              "Biden  1.794325     0.622407           2.489627  0.398340"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KMETXF1EjhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#forming window around tweets that mention trump and issues\n",
        "\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "impeach_sentiment_trump=[]\n",
        "economy_sentiment_trump=[]\n",
        "immigration_sentiment_trump=[]\n",
        "foreign_relations_sentiment_trump=[]\n",
        "for s in impeach_trump:\n",
        "    for i in range(len(s)):\n",
        "        if s[i] =='impeach':\n",
        "            impeach_sentiment_trump.append(TreebankWordDetokenizer().detokenize(s[i-2:i+2]))\n",
        "            \n",
        "for s in economy_trump:\n",
        "    for i in range(len(s)):\n",
        "        if s[i] =='economy':\n",
        "            economy_sentiment_trump.append(TreebankWordDetokenizer().detokenize(s[i-2:i+2]))\n",
        "\n",
        "for s in immigration_trump:\n",
        "    for i in range(len(s)):\n",
        "        if s[i] =='immigration':\n",
        "            immigration_sentiment_trump.append(TreebankWordDetokenizer().detokenize(s[i-2:i+2]))\n",
        "\n",
        "for s in impeach_trump:\n",
        "    for i in range(len(s)):\n",
        "        if s[i] =='foreign_relations':\n",
        "            foreign_relations_sentiment_trump.append(TreebankWordDetokenizer().detokenize(s[i-2:i+2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCoDilgBEjhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#forming window around tweets that mention biden and issues\n",
        "impeach_sentiment_biden=[]\n",
        "economy_sentiment_biden=[]\n",
        "immigration_sentiment_biden=[]\n",
        "foreign_relations_sentiment_biden=[]\n",
        "for s in impeach_biden:\n",
        "    for i in range(len(s)):\n",
        "        if s[i] =='impeach':\n",
        "            impeach_sentiment_biden.append(TreebankWordDetokenizer().detokenize(s[i-2:i+2]))\n",
        "            \n",
        "for s in economy_biden:\n",
        "    for i in range(len(s)):\n",
        "        if s[i] =='economy':\n",
        "            economy_sentiment_biden.append(TreebankWordDetokenizer().detokenize(s[i-2:i+2]))\n",
        "\n",
        "for s in immigration_biden:\n",
        "    for i in range(len(s)):\n",
        "        if s[i] =='immigration':\n",
        "            immigration_sentiment_biden.append(TreebankWordDetokenizer().detokenize(s[i-2:i+2]))\n",
        "\n",
        "for s in foreign_relations_biden:\n",
        "    for i in range(len(s)):\n",
        "        if s[i] =='foreign_relations':\n",
        "            foreign_relations_sentiment_biden.append(TreebankWordDetokenizer().detokenize(s[i-2:i+2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO8RY3cvEjhL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#performing sentiment analysis \n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
        "\n",
        "def sentiment_analysis(list_):\n",
        "\n",
        "    sia = SIA()\n",
        "    r = []\n",
        "\n",
        "    for i in list_:\n",
        "        score_ = sia.polarity_scores(i)\n",
        "        r.append(score_)\n",
        "    sum_=0\n",
        "    for i in range(len(r)):\n",
        "        sum_ = sum_ + r[i]['pos']- r[i]['neg']\n",
        "    return sum_ "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6ITFtc8EjhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#getting lift scores for all key issues for each candidate\n",
        "\n",
        "impeach_sentiment_t= sentiment_analysis(impeach_sentiment_trump)\n",
        "economy_sentiment_t= sentiment_analysis(economy_sentiment_trump)\n",
        "immigration_sentiment_t =sentiment_analysis(immigration_sentiment_trump)\n",
        "foreign_relations_sentiment_t= sentiment_analysis(foreign_relations_sentiment_trump)\n",
        "\n",
        "impeach_sentiment_b = sentiment_analysis(impeach_sentiment_biden)\n",
        "economy_sentiment_b= sentiment_analysis(economy_sentiment_biden)\n",
        "immigration_sentiment_b =sentiment_analysis(immigration_sentiment_biden)\n",
        "foreign_relations_sentiment_b= sentiment_analysis(foreign_relations_sentiment_biden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LQPwUyEjhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [[economy_sentiment_t, immigration_sentiment_t, foreign_relations_sentiment_t, impeach_sentiment_t], [economy_sentiment_b, immigration_sentiment_b, foreign_relations_sentiment_b,impeach_sentiment_b]]\n",
        "sentiment = pd.DataFrame(data, columns = ['Economy', 'Immigration', 'Foreign Relations', 'Impeach'])\n",
        "sentiment.rename(index = {0: \"Trump\", 1:\"Biden\"},  inplace = True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySCVADLGEjhR",
        "colab_type": "code",
        "colab": {},
        "outputId": "545fbdb6-05d6-41bc-84bc-88a331db149b"
      },
      "source": [
        "sentiment"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Economy</th>\n",
              "      <th>Immigration</th>\n",
              "      <th>Foreign Relations</th>\n",
              "      <th>Impeach</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>Trump</td>\n",
              "      <td>0.720</td>\n",
              "      <td>1.235</td>\n",
              "      <td>0.455</td>\n",
              "      <td>0.324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>Biden</td>\n",
              "      <td>-0.401</td>\n",
              "      <td>-0.538</td>\n",
              "      <td>-1.266</td>\n",
              "      <td>0.444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Economy  Immigration  Foreign Relations  Impeach\n",
              "Trump    0.720        1.235              0.455    0.324\n",
              "Biden   -0.401       -0.538             -1.266    0.444"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PURGH45yEjhX",
        "colab_type": "text"
      },
      "source": [
        "### Part E"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zp5M5vREjhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## get top ten cities of each state\n",
        "Michigan = ['Detroit','Grand Rapids','Warren', 'Sterling Heights','Ann Arbor','Lansing','Flint','Dearborn','Livonia','Troy']\n",
        "Pennsylvania = ['Philadelphia','Pittsburgh','Allentown','Erie','Reading','Upper Darby','Scranton','Bethlehem','Lancaster','Millcreek']\n",
        "Wisconsin = ['Milwaukee','Madison','Green Bay','Kenosha','Racine','Appleton','Waukesha','Eau Claire','Oshkosh','Janesville']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73teyB8REjhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## make the city name all lower case\n",
        "mi = []\n",
        "for x in Michigan:\n",
        "    mi.append(x.lower())\n",
        "    \n",
        "pen = []\n",
        "for x in Pennsylvania:\n",
        "    pen.append(x.lower())\n",
        "    \n",
        "wi = []\n",
        "for x in Wisconsin:\n",
        "    wi.append(x.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Z5MQo7Ejhg",
        "colab_type": "code",
        "colab": {},
        "outputId": "9fb94df5-5a8d-494d-8304-935a1e577560"
      },
      "source": [
        "threestates = []\n",
        "for x in tweets['User Location'].unique():\n",
        "    if 'michigan' in str(x).lower() or 'pennsylvania'in str(x).lower() or 'wisconsin' in str(x).lower() or str(x).lower().endswith(', mi') or str(x).lower().endswith('pa') or str(x).lower().endswith('wi') or str(x).lower() in mi or str(x).lower() in pen or str(x).lower() in wi:\n",
        "        threestates.append(x)\n",
        "\n",
        "threestates"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Michigan, USA',\n",
              " 'Pennsylvania',\n",
              " 'Green Bay',\n",
              " 'Pennsylvania, USA',\n",
              " 'Verona WI',\n",
              " 'Altoona PA',\n",
              " 'Wisconsin, USA',\n",
              " 'Lehigh Valley PA',\n",
              " 'DELCO Phila, Pa',\n",
              " 'Philadelphia, PA',\n",
              " 'Eastern PA',\n",
              " 'Warren, PA',\n",
              " 'Butler, PA',\n",
              " 'Philadelphia',\n",
              " 'Somewhere in Pennsylvania!',\n",
              " 'Little Chute, WI',\n",
              " 'Easton, PA',\n",
              " 'Holt, MI',\n",
              " 'Grand Blanc, MI',\n",
              " 'Pittsburgh, PA',\n",
              " 'Tempe, AZ & Door County, WI',\n",
              " 'Waterford, PA',\n",
              " 'Lebanon, PA',\n",
              " 'Monaca, PA',\n",
              " 'Wisconsin, USA ',\n",
              " 'Loganville, PA',\n",
              " 'Michigan U.S.A.',\n",
              " 'Near Pittsburgh PA',\n",
              " 'Western Pa',\n",
              " 'Detroit, MI',\n",
              " 'Huntingdon Valley, PA',\n",
              " 'Oakland County, Mi',\n",
              " 'Cranberry Township, PA',\n",
              " 'Hobart, WI',\n",
              " 'Lancaster, PA',\n",
              " 'Clinton, MI',\n",
              " 'Southfield, MI',\n",
              " 'Michigan',\n",
              " 'Lock Haven, PA',\n",
              " 'Ligonier, PA',\n",
              " 'Davidsville, PA',\n",
              " 'New York / Pennsylvania',\n",
              " 'Mt. Pleasant Michigan',\n",
              " 'Milwaukee',\n",
              " 'Superior, WI',\n",
              " 'Port Huron, MI',\n",
              " 'PA']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTMlUK-3Ejhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for index, row in tweets.iterrows():\n",
        "    if row['User Location'] in threestates:\n",
        "        tweets.loc[index,'User Location'] = 'battleground'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkC81jEEEjho",
        "colab_type": "code",
        "colab": {},
        "outputId": "8655dddf-8666-4134-e993-e953a32026ac"
      },
      "source": [
        "data1 = tweets.copy()\n",
        "data1[data1['User Location'] == 'battleground']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Date</th>\n",
              "      <th>tweets</th>\n",
              "      <th>User Location</th>\n",
              "      <th>hashtag</th>\n",
              "      <th>clean_tweets</th>\n",
              "      <th>word_freq_list</th>\n",
              "      <th>comments_attributes_replace</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "      <td>10/14/2019 0:35</td>\n",
              "      <td>@NBCNews Unfounded?  You people are nuts!  Oh ...</td>\n",
              "      <td>battleground</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>nbcnews unfounded  you people are nuts  oh wai...</td>\n",
              "      <td>[youre, never, mind, wait, people, nuts, nbcne...</td>\n",
              "      <td>youre never mind wait people nuts nbcnews nbc ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "      <td>10/14/2019 0:24</td>\n",
              "      <td>@BillKristol Drunk again? #MAGA2020</td>\n",
              "      <td>battleground</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>billkristol drunk again maga2020</td>\n",
              "      <td>[billkristol, drunk, maga2020]</td>\n",
              "      <td>billkristol drunk trump2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>54</td>\n",
              "      <td>10/14/2019 0:04</td>\n",
              "      <td>@DavidJHarrisJr @realDonaldTrump That would of...</td>\n",
              "      <td>battleground</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>davidjharrisjr realdonaldtrump that would of m...</td>\n",
              "      <td>[better, realdonaldtrump, made, seeing, last, ...</td>\n",
              "      <td>better trump made seeing last hat trump week f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>155</td>\n",
              "      <td>10/13/2019 22:45</td>\n",
              "      <td>No matter how hard they try to hinder our abil...</td>\n",
              "      <td>battleground</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>no matter how hard they try to hinder our abil...</td>\n",
              "      <td>[strong‚Ä¶, hard, positive, train, matter, hinde...</td>\n",
              "      <td>strong‚Ä¶ hard positive train matter hinder http...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>164</td>\n",
              "      <td>10/13/2019 22:38</td>\n",
              "      <td>@thehill @realDonaldTrump You don‚Äôt speak for ...</td>\n",
              "      <td>battleground</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>thehill realdonaldtrump you don‚Äôt speak for th...</td>\n",
              "      <td>[speak, us, maga2020, public, trumpin, magats,...</td>\n",
              "      <td>speak us trump2020 public trumpin trumpts amer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5888</td>\n",
              "      <td>5888</td>\n",
              "      <td>10/11/2019 0:47</td>\n",
              "      <td>I agree, @charliekirk11 !#MAGA2020 https://t.c...</td>\n",
              "      <td>battleground</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>i agree charliekirk11 maga2020 httpstcovo4vppymfe</td>\n",
              "      <td>[agree, charliekirk11, httpstcovo4vppymfe, mag...</td>\n",
              "      <td>agree charliekirk11 httpstcovo4vppymfe trump2020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>5900</td>\n",
              "      <td>10/11/2019 0:46</td>\n",
              "      <td>Minneapolis police officer running against Ilh...</td>\n",
              "      <td>battleground</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>minneapolis police officer running against ilh...</td>\n",
              "      <td>[running, constituents, minneapolis, omar, ilh...</td>\n",
              "      <td>running constituents minneapolis omar ilhan ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5905</td>\n",
              "      <td>5905</td>\n",
              "      <td>10/11/2019 0:44</td>\n",
              "      <td>David Bossie: Impeachment inquiry? No, America...</td>\n",
              "      <td>battleground</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>david bossie impeachment inquiry no americans ...</td>\n",
              "      <td>[americans, bossie, conclusion, httpstcoadqt9o...</td>\n",
              "      <td>americans bossie conclusion httpstcoadqt9otcye...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5908</td>\n",
              "      <td>5908</td>\n",
              "      <td>10/11/2019 0:44</td>\n",
              "      <td>@SpeakerPelosi @RepAdamSchiff Fact:  only way ...</td>\n",
              "      <td>battleground</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>speakerpelosi repadamschiff fact  only way tru...</td>\n",
              "      <td>[realdonaldtrump, speakerpelosi, way, fact, 20...</td>\n",
              "      <td>trump speakerpelosi way fact 2020 impeach reel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5933</td>\n",
              "      <td>5933</td>\n",
              "      <td>10/11/2019 0:39</td>\n",
              "      <td>Time to support the beautiful women of Team #M...</td>\n",
              "      <td>battleground</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>time to support the beautiful women of team ma...</td>\n",
              "      <td>[time, üá∫üá∏üá∫üá∏üá∫üá∏, trump2020, maga2020‚Ä¶, rt, give,...</td>\n",
              "      <td>time üá∫üá∏üá∫üá∏üá∫üá∏ trump trump2020‚Ä¶ rt give follow wo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>144 rows √ó 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0              Date  \\\n",
              "13            13   10/14/2019 0:35   \n",
              "32            32   10/14/2019 0:24   \n",
              "54            54   10/14/2019 0:04   \n",
              "155          155  10/13/2019 22:45   \n",
              "164          164  10/13/2019 22:38   \n",
              "...          ...               ...   \n",
              "5888        5888   10/11/2019 0:47   \n",
              "5900        5900   10/11/2019 0:46   \n",
              "5905        5905   10/11/2019 0:44   \n",
              "5908        5908   10/11/2019 0:44   \n",
              "5933        5933   10/11/2019 0:39   \n",
              "\n",
              "                                                 tweets User Location  \\\n",
              "13    @NBCNews Unfounded?  You people are nuts!  Oh ...  battleground   \n",
              "32                  @BillKristol Drunk again? #MAGA2020  battleground   \n",
              "54    @DavidJHarrisJr @realDonaldTrump That would of...  battleground   \n",
              "155   No matter how hard they try to hinder our abil...  battleground   \n",
              "164   @thehill @realDonaldTrump You don‚Äôt speak for ...  battleground   \n",
              "...                                                 ...           ...   \n",
              "5888  I agree, @charliekirk11 !#MAGA2020 https://t.c...  battleground   \n",
              "5900  Minneapolis police officer running against Ilh...  battleground   \n",
              "5905  David Bossie: Impeachment inquiry? No, America...  battleground   \n",
              "5908  @SpeakerPelosi @RepAdamSchiff Fact:  only way ...  battleground   \n",
              "5933  Time to support the beautiful women of Team #M...  battleground   \n",
              "\n",
              "        hashtag                                       clean_tweets  \\\n",
              "13    #MAGA2020  nbcnews unfounded  you people are nuts  oh wai...   \n",
              "32    #MAGA2020                   billkristol drunk again maga2020   \n",
              "54    #MAGA2020  davidjharrisjr realdonaldtrump that would of m...   \n",
              "155   #MAGA2020  no matter how hard they try to hinder our abil...   \n",
              "164   #MAGA2020  thehill realdonaldtrump you don‚Äôt speak for th...   \n",
              "...         ...                                                ...   \n",
              "5888  #MAGA2020  i agree charliekirk11 maga2020 httpstcovo4vppymfe   \n",
              "5900  #MAGA2020  minneapolis police officer running against ilh...   \n",
              "5905  #MAGA2020  david bossie impeachment inquiry no americans ...   \n",
              "5908  #MAGA2020  speakerpelosi repadamschiff fact  only way tru...   \n",
              "5933  #MAGA2020  time to support the beautiful women of team ma...   \n",
              "\n",
              "                                         word_freq_list  \\\n",
              "13    [youre, never, mind, wait, people, nuts, nbcne...   \n",
              "32                       [billkristol, drunk, maga2020]   \n",
              "54    [better, realdonaldtrump, made, seeing, last, ...   \n",
              "155   [strong‚Ä¶, hard, positive, train, matter, hinde...   \n",
              "164   [speak, us, maga2020, public, trumpin, magats,...   \n",
              "...                                                 ...   \n",
              "5888  [agree, charliekirk11, httpstcovo4vppymfe, mag...   \n",
              "5900  [running, constituents, minneapolis, omar, ilh...   \n",
              "5905  [americans, bossie, conclusion, httpstcoadqt9o...   \n",
              "5908  [realdonaldtrump, speakerpelosi, way, fact, 20...   \n",
              "5933  [time, üá∫üá∏üá∫üá∏üá∫üá∏, trump2020, maga2020‚Ä¶, rt, give,...   \n",
              "\n",
              "                            comments_attributes_replace  \n",
              "13    youre never mind wait people nuts nbcnews nbc ...  \n",
              "32                          billkristol drunk trump2020  \n",
              "54    better trump made seeing last hat trump week f...  \n",
              "155   strong‚Ä¶ hard positive train matter hinder http...  \n",
              "164   speak us trump2020 public trumpin trumpts amer...  \n",
              "...                                                 ...  \n",
              "5888   agree charliekirk11 httpstcovo4vppymfe trump2020  \n",
              "5900  running constituents minneapolis omar ilhan ab...  \n",
              "5905  americans bossie conclusion httpstcoadqt9otcye...  \n",
              "5908  trump speakerpelosi way fact 2020 impeach reel...  \n",
              "5933  time üá∫üá∏üá∫üá∏üá∫üá∏ trump trump2020‚Ä¶ rt give follow wo...  \n",
              "\n",
              "[144 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MijN_GVnEjhs",
        "colab_type": "code",
        "colab": {},
        "outputId": "252e9390-5f49-464e-fed0-f46a3fa475f0"
      },
      "source": [
        "data1 = data1.dropna().copy()\n",
        "data1.loc[data1['User Location'] == 'battleground','tweets'] = 'battleground' + data1['tweets']\n",
        "data1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Date</th>\n",
              "      <th>tweets</th>\n",
              "      <th>User Location</th>\n",
              "      <th>hashtag</th>\n",
              "      <th>clean_tweets</th>\n",
              "      <th>word_freq_list</th>\n",
              "      <th>comments_attributes_replace</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10/14/2019 0:47</td>\n",
              "      <td>Why do they keep electing elites that have mil...</td>\n",
              "      <td>United States</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>why do they keep electing elites that have mil...</td>\n",
              "      <td>[trump2020, maga2020‚Ä¶, millions, keep, themmag...</td>\n",
              "      <td>trump trump2020‚Ä¶ millions keep themtrump dolla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10/14/2019 0:46</td>\n",
              "      <td>No Shame! \\nThanks @carlosrossimc for the vers...</td>\n",
              "      <td>United States</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>no shame \\nthanks carlosrossimc for the verse\\...</td>\n",
              "      <td>[kag, kagchallenge, verse, trump2020, carlosro...</td>\n",
              "      <td>trump trumpchallenge verse trump carlosrossimc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10/14/2019 0:45</td>\n",
              "      <td>@realDonaldTrump @FoxNews needs to dump Wallac...</td>\n",
              "      <td>Boston, MA</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>realdonaldtrump foxnews needs to dump wallace ...</td>\n",
              "      <td>[time, httpstcoaukdrtpmkc, every, wallace, swi...</td>\n",
              "      <td>time httpstcoaukdrtpmkc every immigrationace s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>10/14/2019 0:45</td>\n",
              "      <td>President Trump is 100% Correct on Syria Withd...</td>\n",
              "      <td>Florida of course!</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>president trump is 100 correct on syria withdr...</td>\n",
              "      <td>[last, ‚Äì, stable, ‚Å¶potus‚Å©, geniusüá∫üá∏üá∫üá∏‚Ä¶, refuge...</td>\n",
              "      <td>last ‚Äì stable ‚Å¶potus‚Å© geniusüá∫üá∏üá∫üá∏‚Ä¶ refuge withd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>10/14/2019 0:44</td>\n",
              "      <td>@JoeBiden Poor Joe...#MAGA #MAGA2020</td>\n",
              "      <td>Corpus Christi</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>joebiden poor joemaga maga2020</td>\n",
              "      <td>[maga2020, poor, joemaga, joebiden]</td>\n",
              "      <td>trump2020 poor bidentrump biden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5993</td>\n",
              "      <td>5993</td>\n",
              "      <td>10/11/2019 0:19</td>\n",
              "      <td>Thank you to all my friends for sharing pictur...</td>\n",
              "      <td>Minnesota, USA</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>thank you to all my friends for sharing pictur...</td>\n",
              "      <td>[sharing, videos, minnesota‚Ä¶, thank, ‚Äô, httpst...</td>\n",
              "      <td>sharing videos minnesota‚Ä¶ thank ‚Äô httpstcov83p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5994</td>\n",
              "      <td>5994</td>\n",
              "      <td>10/11/2019 0:19</td>\n",
              "      <td>Thank you to all my friends for sharing pictur...</td>\n",
              "      <td>Minnesota, USA</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>thank you to all my friends for sharing pictur...</td>\n",
              "      <td>[sharing, videos, minnesota‚Ä¶, thank, ‚Äô, friend...</td>\n",
              "      <td>sharing videos minnesota‚Ä¶ thank ‚Äô friends pict...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5995</td>\n",
              "      <td>5995</td>\n",
              "      <td>10/11/2019 0:18</td>\n",
              "      <td>Trump‚Äôs children take in millions overseas as ...</td>\n",
              "      <td>Portland, OR</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>trump‚Äôs children take in millions overseas as ...</td>\n",
              "      <td>[overseas, son, president, httpstcof4j5mupjmb,...</td>\n",
              "      <td>overseas son president httpstcof4j5mupjmb trum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5997</td>\n",
              "      <td>5997</td>\n",
              "      <td>10/11/2019 0:17</td>\n",
              "      <td>üö®BREAKINGüö®\\n#Whistleblower Worked With #JoeBid...</td>\n",
              "      <td>USA</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>üö®breakingüö®\\nwhistleblower worked with joebiden...</td>\n",
              "      <td>[httpstcox0cjtigzhe, joebidencorruption, whist...</td>\n",
              "      <td>httpstcox0cjtigzhe bidencorruption whistleblow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5998</td>\n",
              "      <td>5998</td>\n",
              "      <td>10/11/2019 0:17</td>\n",
              "      <td>Gosh, imagine that- a spineless business failu...</td>\n",
              "      <td>Freehold, NJ</td>\n",
              "      <td>#MAGA2020</td>\n",
              "      <td>gosh imagine that a spineless business failure...</td>\n",
              "      <td>[bill‚Ä¶, httpstco23ohvweeez, gosh, stiffing, cr...</td>\n",
              "      <td>bill‚Ä¶ httpstco23ohvweeez gosh stiffing credito...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3975 rows √ó 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0             Date  \\\n",
              "0              0  10/14/2019 0:47   \n",
              "1              1  10/14/2019 0:46   \n",
              "3              3  10/14/2019 0:45   \n",
              "4              4  10/14/2019 0:45   \n",
              "5              5  10/14/2019 0:44   \n",
              "...          ...              ...   \n",
              "5993        5993  10/11/2019 0:19   \n",
              "5994        5994  10/11/2019 0:19   \n",
              "5995        5995  10/11/2019 0:18   \n",
              "5997        5997  10/11/2019 0:17   \n",
              "5998        5998  10/11/2019 0:17   \n",
              "\n",
              "                                                 tweets       User Location  \\\n",
              "0     Why do they keep electing elites that have mil...       United States   \n",
              "1     No Shame! \\nThanks @carlosrossimc for the vers...       United States   \n",
              "3     @realDonaldTrump @FoxNews needs to dump Wallac...          Boston, MA   \n",
              "4     President Trump is 100% Correct on Syria Withd...  Florida of course!   \n",
              "5                  @JoeBiden Poor Joe...#MAGA #MAGA2020      Corpus Christi   \n",
              "...                                                 ...                 ...   \n",
              "5993  Thank you to all my friends for sharing pictur...      Minnesota, USA   \n",
              "5994  Thank you to all my friends for sharing pictur...      Minnesota, USA   \n",
              "5995  Trump‚Äôs children take in millions overseas as ...        Portland, OR   \n",
              "5997  üö®BREAKINGüö®\\n#Whistleblower Worked With #JoeBid...                 USA   \n",
              "5998  Gosh, imagine that- a spineless business failu...        Freehold, NJ   \n",
              "\n",
              "        hashtag                                       clean_tweets  \\\n",
              "0     #MAGA2020  why do they keep electing elites that have mil...   \n",
              "1     #MAGA2020  no shame \\nthanks carlosrossimc for the verse\\...   \n",
              "3     #MAGA2020  realdonaldtrump foxnews needs to dump wallace ...   \n",
              "4     #MAGA2020  president trump is 100 correct on syria withdr...   \n",
              "5     #MAGA2020                     joebiden poor joemaga maga2020   \n",
              "...         ...                                                ...   \n",
              "5993  #MAGA2020  thank you to all my friends for sharing pictur...   \n",
              "5994  #MAGA2020  thank you to all my friends for sharing pictur...   \n",
              "5995  #MAGA2020  trump‚Äôs children take in millions overseas as ...   \n",
              "5997  #MAGA2020  üö®breakingüö®\\nwhistleblower worked with joebiden...   \n",
              "5998  #MAGA2020  gosh imagine that a spineless business failure...   \n",
              "\n",
              "                                         word_freq_list  \\\n",
              "0     [trump2020, maga2020‚Ä¶, millions, keep, themmag...   \n",
              "1     [kag, kagchallenge, verse, trump2020, carlosro...   \n",
              "3     [time, httpstcoaukdrtpmkc, every, wallace, swi...   \n",
              "4     [last, ‚Äì, stable, ‚Å¶potus‚Å©, geniusüá∫üá∏üá∫üá∏‚Ä¶, refuge...   \n",
              "5                   [maga2020, poor, joemaga, joebiden]   \n",
              "...                                                 ...   \n",
              "5993  [sharing, videos, minnesota‚Ä¶, thank, ‚Äô, httpst...   \n",
              "5994  [sharing, videos, minnesota‚Ä¶, thank, ‚Äô, friend...   \n",
              "5995  [overseas, son, president, httpstcof4j5mupjmb,...   \n",
              "5997  [httpstcox0cjtigzhe, joebidencorruption, whist...   \n",
              "5998  [bill‚Ä¶, httpstco23ohvweeez, gosh, stiffing, cr...   \n",
              "\n",
              "                            comments_attributes_replace  \n",
              "0     trump trump2020‚Ä¶ millions keep themtrump dolla...  \n",
              "1     trump trumpchallenge verse trump carlosrossimc...  \n",
              "3     time httpstcoaukdrtpmkc every immigrationace s...  \n",
              "4     last ‚Äì stable ‚Å¶potus‚Å© geniusüá∫üá∏üá∫üá∏‚Ä¶ refuge withd...  \n",
              "5                       trump2020 poor bidentrump biden  \n",
              "...                                                 ...  \n",
              "5993  sharing videos minnesota‚Ä¶ thank ‚Äô httpstcov83p...  \n",
              "5994  sharing videos minnesota‚Ä¶ thank ‚Äô friends pict...  \n",
              "5995  overseas son president httpstcof4j5mupjmb trum...  \n",
              "5997  httpstcox0cjtigzhe bidencorruption whistleblow...  \n",
              "5998  bill‚Ä¶ httpstco23ohvweeez gosh stiffing credito...  \n",
              "\n",
              "[3975 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrX40ApyEjiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "people_trump = ['trump','battleground']\n",
        "trump_df = pd.DataFrame(columns = people_trump)\n",
        "\n",
        "def candidates_mentioned(item):\n",
        "    if p.lower() in item.lower():\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "      \n",
        "for p in people_trump:\n",
        "    trump_df[p] = data1['tweets'].apply(candidates_mentioned)\n",
        "    \n",
        "    \n",
        "    \n",
        "people_dem = ['biden','battleground']\n",
        "dem_df = pd.DataFrame(columns = people_dem)\n",
        "\n",
        "def candidates_mentioned(item):\n",
        "    if p.lower() in item.lower():\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "      \n",
        "for p in people_dem:\n",
        "    dem_df[p] = data1['tweets'].apply(candidates_mentioned)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcrKvZfIEjiJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "20dafe4a-ee86-4660-cf1d-8afe9670a289"
      },
      "source": [
        "liftratio1=pd.DataFrame(columns = people_trump)\n",
        "for i in range(len(people_trump)):\n",
        "    new_list = []\n",
        "    for j in range(len(people_trump)):\n",
        "        if (i!=j):\n",
        "            numerator = ((trump_df[people_trump[i]] + trump_df[people_trump[j]]) > 1).sum()\n",
        "            denominator = trump_df[people_trump[j]].sum()*trump_df[people_trump[i]].sum()\n",
        "            lift = numerator*len(trump_df)/denominator\n",
        "            liftratio1.loc[people_trump[i],people_trump[j]] = lift\n",
        "print ('Below are the lift ratios among Trump and battleground')\n",
        "liftratio1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Below are the lift ratios among Trump and battleground\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>trump</th>\n",
              "      <th>battleground</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>trump</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>battleground</td>\n",
              "      <td>1.0759</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               trump battleground\n",
              "trump            NaN       1.0759\n",
              "battleground  1.0759          NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P75joA6EjiL",
        "colab_type": "code",
        "colab": {},
        "outputId": "1d246e86-984f-4848-f82e-f5d55bc04a32"
      },
      "source": [
        "liftratio2=pd.DataFrame(columns = people_dem)\n",
        "for i in range(len(people_dem)):\n",
        "    new_list = []\n",
        "    for j in range(len(people_dem)):\n",
        "        if (i!=j):\n",
        "            numerator = ((dem_df[people_dem[i]] + dem_df[people_dem[j]]) > 1).sum()\n",
        "            denominator = dem_df[people_dem[j]].sum()*dem_df[people_dem[i]].sum()\n",
        "            lift = numerator*len(dem_df)/denominator\n",
        "            liftratio2.loc[people_dem[i],people_dem[j]] = lift\n",
        "print ('Below are the lift ratios among Biden and battleground')\n",
        "liftratio2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Below are the lift ratios among Biden and battleground\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>biden</th>\n",
              "      <th>battleground</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>biden</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>battleground</td>\n",
              "      <td>1.886</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              biden battleground\n",
              "biden           NaN        1.886\n",
              "battleground  1.886          NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeeoYSpwEjiO",
        "colab_type": "text"
      },
      "source": [
        "## Lift analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnfTml_ZEjiO",
        "colab_type": "code",
        "colab": {},
        "outputId": "10d70e21-f8cd-4e9a-a027-85f7496090a0"
      },
      "source": [
        "liftdf = pd.DataFrame(index=['Battleground'],columns=['Trump','Biden'])\n",
        "liftdf.iloc[0,0]=liftratio1.iloc[0,1]\n",
        "liftdf.iloc[0,1]=liftratio2.iloc[0,1]\n",
        "liftdf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Trump</th>\n",
              "      <th>Biden</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>Battleground</td>\n",
              "      <td>1.0759</td>\n",
              "      <td>1.886</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Trump  Biden\n",
              "Battleground  1.0759  1.886"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXmhCWS_EjiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data2 = data1[data1['User Location'] == 'battleground']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjbme-w7EjiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the compound sentiment score of tweets mentioned Trump\n",
        "trumpsenti=[]\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "for index, row in data2.iterrows():\n",
        "    if 'trump' in row['tweets'].lower():\n",
        "        vs = analyzer.polarity_scores(row['tweets'])\n",
        "        trumpsenti.append(vs['compound'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87epD3HvEjiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the compound sentiment score of tweets mentioned Biden\n",
        "demsenti=[]\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "for index, row in data2.iterrows():\n",
        "    if 'biden' in row['tweets'].lower():\n",
        "        vs = analyzer.polarity_scores(row['tweets'])\n",
        "        demsenti.append((vs['compound']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWDxpRw7EjiX",
        "colab_type": "code",
        "colab": {},
        "outputId": "d4669bc7-bcad-4655-a58d-5ff9f218328f"
      },
      "source": [
        "# take the average semtiment score of each tweet\n",
        "sentimentdf = pd.DataFrame(index=['Battleground'],columns=['Trump','Biden'])\n",
        "sentimentdf.iloc[0,0]=np.mean(trumpsenti)\n",
        "sentimentdf.iloc[0,1]=np.mean(demsenti)\n",
        "sentimentdf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Trump</th>\n",
              "      <th>Biden</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>Battleground</td>\n",
              "      <td>0.158118</td>\n",
              "      <td>0.0489545</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Trump      Biden\n",
              "Battleground  0.158118  0.0489545"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGRnRKQGEjiZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "8ad60d2a-3330-4df8-bdb1-137e1b8636fb"
      },
      "source": [
        "# a more detailed report of people's sentiment when they talk about Trump\n",
        "trumppos = 0\n",
        "trumpneg = 0\n",
        "for x in trumpsenti:\n",
        "    if x>0:\n",
        "        trumppos+=1\n",
        "    if x<0:\n",
        "        trumpneg+=1\n",
        "trumppos = trumppos/len(trumpsenti)\n",
        "trumpneg = trumpneg/len(trumpsenti)\n",
        "\n",
        "\n",
        "print(str(trumppos*100) +\"% of tweets have postive sentiments regarding to Trump in battleground.\")\n",
        "print(str((1-trumpneg-trumppos)*100) +\"% of tweets have neutral sentiments regarding to Trump in battleground.\")\n",
        "print(str(trumpneg*100) +\"% of tweets have negitive sentiments regarding to Trump in battleground.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44.776119402985074% of tweets have postive sentiments regarding to Trump in battleground.\n",
            "35.82089552238806% of tweets have negitive sentiments regarding to Trump in battleground.\n",
            "19.402985074626866% of tweets have negitive sentiments regarding to Trump in battleground.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDw_dSzuEjic",
        "colab_type": "code",
        "colab": {},
        "outputId": "a8e248f1-ba7d-4f9e-e0e7-f181c7f116b9"
      },
      "source": [
        "# a more detailed report of people's sentiment when they talk about Biden\n",
        "bidenpos = 0\n",
        "bidenneg = 0\n",
        "for x in demsenti:\n",
        "    if x>0:\n",
        "        bidenpos+=1\n",
        "    if x<0:\n",
        "        bidenneg+=1\n",
        "        \n",
        "bidenpos = bidenpos/len(demsenti)\n",
        "bidenpos = bidenneg/len(demsenti)\n",
        "\n",
        "\n",
        "print(str(bidenpos*100) +\"% of tweets have postive sentiments regarding to Biden in battleground.\")\n",
        "print(str((1-bidenpos-bidenpos)*100) +\"% of tweets have neutral sentiments regarding to Biden in battleground.\")\n",
        "print(str(bidenpos*100) +\"% of tweets have negitive sentiments regarding to Biden in battleground.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27.27272727272727% of tweets have postive sentiments regarding to Biden in battleground.\n",
            "45.45454545454546% of tweets have negitive sentiments regarding to Biden in battleground.\n",
            "27.27272727272727% of tweets have negitive sentiments regarding to Biden in battleground.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBzIEQVPFNij",
        "colab_type": "text"
      },
      "source": [
        "# Part F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCXlJC_-FRPc",
        "colab_type": "text"
      },
      "source": [
        "### According to the lift analysis, Trump is associated more with immigration and impeach issues than Biden. While Biden is more associated with economy and foreign relations issues. According to the sentiment analysis, people have very diverse sentiments of Trump and Biden on different issues. As for economy issue, people‚Äôs overall sentiment of Trump is positive. On the other hand, Biden is not favorable because the sentiment score is negative. For immigration issue, Biden is favorable, and Trump is not liked. As for foreign relations, both candidates are not favorable. However, people still prefer Trump compared to Biden. For impeach issue, Trump is more favorable than Biden. And people‚Äôssentiment of Biden is neutral on impeach issue.Trump should improve his reputation on immigration and foreign relation issues, because on these issues Biden is favorable. Our recommendation is that he should not post too many twittes abouthis politics. Even he wants to post something on Twitter, he should not show the aggressiveness because it will make people dislike him. Especially for immigration and foreign relation issues, on whichpeople show negative sentiments. As for Biden, he should work on improving his recognition on solvingeconomy and impeach issues, since Trump is preferred compared to him on these two issues. What‚Äôs more, he should increase the frequency of posting twittes. Because Trump posts a lot, and it will shift the focus away from him.  According to the result of lift analysis Trump is not frequently discussed in Michigan, Pennsylvania and Wisconsin. The probability of Trump been discussed is less than random selection. Compared to Trump, Biden is much more likely to be discussed by people in Michigan, Pennsylvania and Wisconsin. The probability of Biden been discussed is significantly higher than random selection. According to the result of sentiment analysis, for people in Michigan, Pennsylvania and Wisconsin, theirsentiments about Trump is more positive than their sentiments about Biden. In other words, Trump is more favorable in Michigan, Pennsylvania and Wisconsin, compared to Biden. After combining the lift analysis and the sentiment analysis, we are confidence to conclude that although Biden is mentioned more in people‚Äôs discussions, it is likely that those mentions are close to neutral sentiments. Although Trump is mentioned less frequently, people in Michigan, Pennsylvania and Wisconsin like him more than Biden. Trump should give more speeches in Michigan, Pennsylvania and Wisconsin. Because he is favorable compared to Biden. By giving more speeches, people will discuss him more, and it is beneficial. Biden should participate more on Twitter and speak for people‚Äôs benefits; therefore, he would have a chance to have higher sentiment score than Trump."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9eEvs0YFSz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}