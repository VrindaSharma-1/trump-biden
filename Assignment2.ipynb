{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('6ktweets.csv')\n",
    "\n",
    "def remove_punctuation(item):\n",
    "    for p in punctuation:\n",
    "        item = item.lstrip().replace(p,'')\n",
    "    return item\n",
    "\n",
    "def conv_lowercase(x):\n",
    "    return x.lower()\n",
    "\n",
    "tweets['clean_tweets'] = tweets['tweets'].apply(remove_punctuation).apply(conv_lowercase)\n",
    "#tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()\n",
    "tweets['word_freq_list'] = tweets['clean_tweets'].apply(word_tokenize).apply(set).apply(list)\n",
    "\n",
    "# Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(s):\n",
    "    return [w for w in s if not w in stop_words] \n",
    "\n",
    "tweets['word_freq_list'] = tweets['word_freq_list'].apply(remove_stopwords)\n",
    "\n",
    "# Creating a list of all the words in the comments to count word frequency in the next step\n",
    "count = []\n",
    "for i in range(len(tweets)):\n",
    "    count+=tweets['word_freq_list'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching the frequency of words\n",
    "from nltk import FreqDist\n",
    "word_freq = nltk.FreqDist(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identified key issues\n",
    "\n",
    "#trump issues\n",
    "immigration = ['mexican', 'wall', 'immigrate', 'mexico', 'illegals', 'immigrants', 'immigrant']\n",
    "impeach = ['impeachment', 'impeached', 'trumpimpeachment', 'impeachtrump']\n",
    "foreign_relations = ['ukraine', 'isis', 'syria', 'china' ,'iran']\n",
    "\n",
    "#biden issues\n",
    "economy = ['job', 'jobs', 'money', 'taxes', 'taxpayer', 'economys', 'trumpeconomy']\n",
    "education = [ 'college', 'school' ,'educate' ,'students' , 'student']\n",
    "gun_control = ['control','weapons', 'weapon','guns', 'gun']\n",
    "\n",
    "#replacements for trump and biden\n",
    "trump = ['donaldtrump', 'realdonaldtrump',  'trump2020','trumps', 'donald' ]\n",
    "biden = ['joebiden', 'joes','bidens', 'joe']\n",
    "\n",
    "attributes = immigration + impeach+ foreign_relations + economy + trump + biden +education + gun_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing words with key issues\n",
    "key_issues = pd.DataFrame()\n",
    "key_issues['attribute'] = attributes\n",
    "key_issues['general_attribute'] = ''\n",
    "\n",
    "key_issues['general_attribute'][0:len(immigration)] = 'immigration'\n",
    "key_issues['general_attribute'][len(immigration):len(immigration)+len(impeach)] = 'impeach'\n",
    "key_issues['general_attribute'][len(immigration)+len(impeach):len(immigration)+len(impeach)+len(foreign_relations)] = 'foreign_relations'\n",
    "key_issues['general_attribute'][len(immigration)+len(impeach)+len(foreign_relations):len(immigration)+len(impeach)+len(foreign_relations)+len(economy)] = 'economy'\n",
    "key_issues['general_attribute'][len(immigration)+len(impeach)+len(foreign_relations)+ len(economy):len(immigration)+len(impeach)+len(foreign_relations)+len(economy)+len(trump)] = 'trump'\n",
    "key_issues['general_attribute'][len(immigration)+len(impeach)+len(foreign_relations)+len(economy)+len(trump):len(immigration)+len(impeach)+len(foreign_relations)+len(economy)+len(trump)+len(biden)] = 'biden'\n",
    "key_issues['general_attribute'][len(immigration)+len(impeach)+len(foreign_relations)+len(economy)+len(trump)+ len(biden):len(immigration)+len(impeach)+len(foreign_relations)+len(economy)+len(trump)+len(biden) + len(education)] = 'education'\n",
    "key_issues['general_attribute'][len(immigration)+len(impeach)+len(foreign_relations)+len(economy)+len(trump)+ len(biden)+ len(gun_control):len(immigration)+len(impeach)+len(foreign_relations)+len(economy)+len(trump)+len(biden) + len(education)+len(gun_control)] = 'gun_control'\n",
    "#key_issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_to_attributes(s):\n",
    "    s = \" \".join(str(x) for x in s)\n",
    "    for i in key_issues.index.values:\n",
    "        s = s.replace(key_issues[\"attribute\"][i].lower(),key_issues[\"general_attribute\"][i].lower())\n",
    "    return s\n",
    "\n",
    "tweets['comments_attributes_replace'] = tweets['word_freq_list'].apply(word_to_attributes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.To isolate a candidate and an issue, you have to write a parser that selects tweets that mention a candidate, takes a window around an issue, and chops off everything else, as shown in class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making list of tweets that mention trump and list of tweets that mention biden\n",
    "all_ = tweets['comments_attributes_replace'].apply(word_tokenize).apply(set).apply(list)\n",
    "all_ = all_.tolist()\n",
    "t =[]\n",
    "b =[]\n",
    "for i in all_: \n",
    "    for j in set(i):\n",
    "        if j == 'trump':\n",
    "            t.append(i)\n",
    "        elif j == 'biden':\n",
    "            b.append(i)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating total no of tweets that mention each of these key issues\n",
    "economy =[]\n",
    "immigration =[]\n",
    "foreign_relations=[]\n",
    "impeach=[]\n",
    "for j in all_:\n",
    "    for k in j:\n",
    "        if k == 'economy':\n",
    "            economy.append(j)\n",
    "        if k == 'immigration':\n",
    "            immigration.append(j)\n",
    "        if k =='foreign_relations':\n",
    "            foreign_relations.append(j)\n",
    "        if k == 'impeach':\n",
    "            impeach.append(j) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating total number of tweets that mention both key issues and trump\n",
    "economy_trump =[]\n",
    "immigration_trump =[]\n",
    "foreign_relations_trump=[]\n",
    "impeach_trump =[]\n",
    "\n",
    "for j in t:\n",
    "    for k in j:\n",
    "        if k == 'economy':\n",
    "            economy_trump.append(j)\n",
    "        if k == 'immigration':\n",
    "            immigration_trump.append(j)\n",
    "        if k =='foreign_relations':\n",
    "            foreign_relations_trump.append(j)\n",
    "        if k == 'impeach':\n",
    "            impeach_trump.append(j)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating total number of tweets that mention both key issues and biden\n",
    "economy_biden =[]\n",
    "immigration_biden =[]\n",
    "foreign_relations_biden=[]\n",
    "impeach_biden =[]\n",
    "\n",
    "for c in b:\n",
    "    for b1 in set(c):\n",
    "        if b1 == 'economy':\n",
    "            economy_biden.append(c)\n",
    "            continue;\n",
    "        if b1 == 'immigration':\n",
    "            immigration_biden.append(c)\n",
    "            continue; \n",
    "        if b1 =='foreign_relations':\n",
    "            foreign_relations_biden.append(c) \n",
    "            continue;\n",
    "        if b1 == 'impeach':\n",
    "            impeach_biden.append(c)  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lift analysis for trump and biden\n",
    "\n",
    "#trump\n",
    "lift_economy_trump = (len(tweets)*len(economy_trump))/(len(t)*len(economy))\n",
    "lift_immigration_trump = (len(tweets)*len(immigration_trump))/(len(t)*len(immigration))\n",
    "lift_foriegn_relations_trump = (len(tweets)*len(foreign_relations_trump))/(len(t)*len(foreign_relations))\n",
    "lift_impeach_trump = (len(tweets)*len(impeach_trump))/(len(t)*len(impeach))\n",
    "\n",
    "#biden\n",
    "lift_economy_biden = (len(tweets)*len(economy_biden))/(len(b)*len(economy))\n",
    "lift_immigration_biden = (len(tweets)*len(immigration_biden))/(len(b)*len(immigration))\n",
    "lift_foriegn_relations_biden = (len(tweets)*len(foreign_relations_biden))/(len(b)*len(foreign_relations))\n",
    "lift_impeach_biden = (len(tweets)*len(impeach_biden))/(len(b)*len(impeach))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[lift_economy_trump, lift_immigration_trump, lift_foriegn_relations_trump, lift_impeach_trump], [lift_economy_biden, lift_immigration_biden, lift_foriegn_relations_biden,lift_impeach_biden]]\n",
    "lift = pd.DataFrame(data, columns = ['Economy', 'Immigration', 'Foreign Relations', 'Impeach'])\n",
    "lift.rename(index = {0: \"Trump\", 1:\"Biden\"},  inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Economy</th>\n",
       "      <th>Immigration</th>\n",
       "      <th>Foreign Relations</th>\n",
       "      <th>Impeach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>0.677630</td>\n",
       "      <td>1.157184</td>\n",
       "      <td>1.317904</td>\n",
       "      <td>1.712633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biden</th>\n",
       "      <td>1.794325</td>\n",
       "      <td>0.622407</td>\n",
       "      <td>2.489627</td>\n",
       "      <td>0.398340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Economy  Immigration  Foreign Relations   Impeach\n",
       "Trump  0.677630     1.157184           1.317904  1.712633\n",
       "Biden  1.794325     0.622407           2.489627  0.398340"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming window around tweets that mention trump and issues\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "impeach_sentiment_trump=[]\n",
    "economy_sentiment_trump=[]\n",
    "immigration_sentiment_trump=[]\n",
    "foreign_relations_sentiment_trump=[]\n",
    "for s in impeach_trump:\n",
    "    for i in range(len(s)):\n",
    "        if s[i] =='impeach':\n",
    "            impeach_sentiment_trump.append(TreebankWordDetokenizer().detokenize(s[i-2:i+2]))\n",
    "            \n",
    "for s in economy_trump:\n",
    "    for i in range(len(s)):\n",
    "        if s[i] =='economy':\n",
    "            economy_sentiment_trump.append(TreebankWordDetokenizer().detokenize(s[i-2:i+2]))\n",
    "\n",
    "for s in immigration_trump:\n",
    "    for i in range(len(s)):\n",
    "        if s[i] =='immigration':\n",
    "            immigration_sentiment_trump.append(TreebankWordDetokenizer().detokenize(s[i-2:i+2]))\n",
    "\n",
    "for s in impeach_trump:\n",
    "    for i in range(len(s)):\n",
    "        if s[i] =='foreign_relations':\n",
    "            foreign_relations_sentiment_trump.append(TreebankWordDetokenizer().detokenize(s[i-2:i+2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forming window around tweets that mention biden and issues\n",
    "impeach_sentiment_biden=[]\n",
    "economy_sentiment_biden=[]\n",
    "immigration_sentiment_biden=[]\n",
    "foreign_relations_sentiment_biden=[]\n",
    "for s in impeach_biden:\n",
    "    for i in range(len(s)):\n",
    "        if s[i] =='impeach':\n",
    "            impeach_sentiment_biden.append(TreebankWordDetokenizer().detokenize(s[i-2:i+2]))\n",
    "            \n",
    "for s in economy_biden:\n",
    "    for i in range(len(s)):\n",
    "        if s[i] =='economy':\n",
    "            economy_sentiment_biden.append(TreebankWordDetokenizer().detokenize(s[i-2:i+2]))\n",
    "\n",
    "for s in immigration_biden:\n",
    "    for i in range(len(s)):\n",
    "        if s[i] =='immigration':\n",
    "            immigration_sentiment_biden.append(TreebankWordDetokenizer().detokenize(s[i-2:i+2]))\n",
    "\n",
    "for s in foreign_relations_biden:\n",
    "    for i in range(len(s)):\n",
    "        if s[i] =='foreign_relations':\n",
    "            foreign_relations_sentiment_biden.append(TreebankWordDetokenizer().detokenize(s[i-2:i+2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing sentiment analysis \n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "def sentiment_analysis(list_):\n",
    "\n",
    "    sia = SIA()\n",
    "    r = []\n",
    "\n",
    "    for i in list_:\n",
    "        score_ = sia.polarity_scores(i)\n",
    "        r.append(score_)\n",
    "    sum_=0\n",
    "    for i in range(len(r)):\n",
    "        sum_ = sum_ + r[i]['pos']- r[i]['neg']\n",
    "    return sum_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting lift scores for all key issues for each candidate\n",
    "\n",
    "impeach_sentiment_t= sentiment_analysis(impeach_sentiment_trump)\n",
    "economy_sentiment_t= sentiment_analysis(economy_sentiment_trump)\n",
    "immigration_sentiment_t =sentiment_analysis(immigration_sentiment_trump)\n",
    "foreign_relations_sentiment_t= sentiment_analysis(foreign_relations_sentiment_trump)\n",
    "\n",
    "impeach_sentiment_b = sentiment_analysis(impeach_sentiment_biden)\n",
    "economy_sentiment_b= sentiment_analysis(economy_sentiment_biden)\n",
    "immigration_sentiment_b =sentiment_analysis(immigration_sentiment_biden)\n",
    "foreign_relations_sentiment_b= sentiment_analysis(foreign_relations_sentiment_biden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[economy_sentiment_t, immigration_sentiment_t, foreign_relations_sentiment_t, impeach_sentiment_t], [economy_sentiment_b, immigration_sentiment_b, foreign_relations_sentiment_b,impeach_sentiment_b]]\n",
    "sentiment = pd.DataFrame(data, columns = ['Economy', 'Immigration', 'Foreign Relations', 'Impeach'])\n",
    "sentiment.rename(index = {0: \"Trump\", 1:\"Biden\"},  inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Economy</th>\n",
       "      <th>Immigration</th>\n",
       "      <th>Foreign Relations</th>\n",
       "      <th>Impeach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Trump</th>\n",
       "      <td>0.544</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.455</td>\n",
       "      <td>2.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biden</th>\n",
       "      <td>0.516</td>\n",
       "      <td>0.583</td>\n",
       "      <td>-0.888</td>\n",
       "      <td>0.444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Economy  Immigration  Foreign Relations  Impeach\n",
       "Trump    0.544        0.474              0.455    2.074\n",
       "Biden    0.516        0.583             -0.888    0.444"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
